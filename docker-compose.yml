version: '3.8'

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: excuse-backend
    restart: unless-stopped
    environment:
      - LLM_PROXY_URL=https://llm-proxy.densematrix.ai
      - LLM_PROXY_KEY=sk-wskhgeyawc
      - LLM_MODEL=gemini-3-flash-preview
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/health')\""]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - excuse-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: excuse-frontend
    restart: unless-stopped
    ports:
      - "3010:80"
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - excuse-network

networks:
  excuse-network:
    driver: bridge
